{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 393,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "outputs": [
    {
     "data": {
      "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_train_df = train_data['Survived']\n",
    "print(y_train_df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "outputs": [],
   "source": [
    "def normalize(xi, range_min, range_max):\n",
    "    return (xi - range_min) / (range_max - range_min)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "outputs": [],
   "source": [
    "def convert_data(dataset):\n",
    "\n",
    "    new_data = dataset.PassengerId\n",
    "\n",
    "    # PClass to one hot encoding\n",
    "    x1_train_df = pd.get_dummies(dataset.Pclass)\n",
    "    x1_train_df = x1_train_df.set_axis([f'IsPClass{i}' for i in range(1, 4)], axis=1)\n",
    "    new_data = pd.concat([new_data, x1_train_df], axis=1)\n",
    "\n",
    "    # Gender to one hot encoding\n",
    "    x1_train_df = pd.get_dummies(dataset.Sex)\n",
    "    x1_train_df = x1_train_df.set_axis(['Female', 'Male'], axis=1)\n",
    "    new_data = pd.concat([new_data, x1_train_df], axis=1)\n",
    "\n",
    "    # Amount of siblings to continuous variable\n",
    "    x1_train_df = dataset[['SibSp']].copy()\n",
    "    x1_train_df = x1_train_df.apply(lambda cell: normalize(cell, min(x1_train_df.SibSp), max(x1_train_df.SibSp)), axis=0)\n",
    "    new_data = pd.concat([new_data, x1_train_df], axis=1)\n",
    "\n",
    "    # Age\n",
    "    num_age_bins = 10\n",
    "    age_bin_labels = [f'Bin {i}' for i in range(num_age_bins)]\n",
    "    age_bins = dataset[['Age']].copy()\n",
    "    age_bins['Age'] = pd.cut(age_bins['Age'], bins=num_age_bins, include_lowest=True, labels=age_bin_labels)\n",
    "    age_bins['Age'] = age_bins['Age'].cat.add_categories('missing value').fillna('missing value')\n",
    "    age_bin_dummies = pd.get_dummies(age_bins)\n",
    "    new_data = pd.concat([new_data, age_bin_dummies], axis=1)\n",
    "\n",
    "    # Fare\n",
    "    num_fare_bins = 25\n",
    "    fare_bin_labels = [f'FBin {i}' for i in range(num_fare_bins)]\n",
    "    fare_bins = dataset[['Fare']].copy()\n",
    "    fare_bins['Fare']= pd.cut(fare_bins['Fare'], bins=num_fare_bins, include_lowest=True, labels=fare_bin_labels)\n",
    "    fare_bin_dummies = pd.get_dummies(pd.DataFrame(fare_bins))\n",
    "    new_data = pd.concat([new_data, fare_bin_dummies], axis=1)\n",
    "\n",
    "    return new_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "outputs": [
    {
     "data": {
      "text/plain": "   PassengerId  IsPClass1  IsPClass2  IsPClass3  Female  Male  SibSp  \\\n0            1          0          0          1       0     1  0.125   \n1            2          1          0          0       1     0  0.125   \n2            3          0          0          1       1     0  0.000   \n3            4          1          0          0       1     0  0.125   \n4            5          0          0          1       0     1  0.000   \n\n   Age_Bin 0  Age_Bin 1  Age_Bin 2  ...  Fare_FBin 15  Fare_FBin 16  \\\n0          0          0          1  ...             0             0   \n1          0          0          0  ...             0             0   \n2          0          0          0  ...             0             0   \n3          0          0          0  ...             0             0   \n4          0          0          0  ...             0             0   \n\n   Fare_FBin 17  Fare_FBin 18  Fare_FBin 19  Fare_FBin 20  Fare_FBin 21  \\\n0             0             0             0             0             0   \n1             0             0             0             0             0   \n2             0             0             0             0             0   \n3             0             0             0             0             0   \n4             0             0             0             0             0   \n\n   Fare_FBin 22  Fare_FBin 23  Fare_FBin 24  \n0             0             0             0  \n1             0             0             0  \n2             0             0             0  \n3             0             0             0  \n4             0             0             0  \n\n[5 rows x 43 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>IsPClass1</th>\n      <th>IsPClass2</th>\n      <th>IsPClass3</th>\n      <th>Female</th>\n      <th>Male</th>\n      <th>SibSp</th>\n      <th>Age_Bin 0</th>\n      <th>Age_Bin 1</th>\n      <th>Age_Bin 2</th>\n      <th>...</th>\n      <th>Fare_FBin 15</th>\n      <th>Fare_FBin 16</th>\n      <th>Fare_FBin 17</th>\n      <th>Fare_FBin 18</th>\n      <th>Fare_FBin 19</th>\n      <th>Fare_FBin 20</th>\n      <th>Fare_FBin 21</th>\n      <th>Fare_FBin 22</th>\n      <th>Fare_FBin 23</th>\n      <th>Fare_FBin 24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.125</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.125</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.125</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 43 columns</p>\n</div>"
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_df = convert_data(train_data)\n",
    "x_test_df = convert_data(test_data)\n",
    "\n",
    "x_train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'IsPClass1', 'IsPClass2', 'IsPClass3', 'Female', 'Male',\n",
      "       'SibSp', 'Age_Bin 0', 'Age_Bin 1', 'Age_Bin 2', 'Age_Bin 3',\n",
      "       'Age_Bin 4', 'Age_Bin 5', 'Age_Bin 6', 'Age_Bin 7', 'Age_Bin 8',\n",
      "       'Age_Bin 9', 'Age_missing value', 'Fare_FBin 0', 'Fare_FBin 1',\n",
      "       'Fare_FBin 2', 'Fare_FBin 3', 'Fare_FBin 4', 'Fare_FBin 5',\n",
      "       'Fare_FBin 6', 'Fare_FBin 7', 'Fare_FBin 8', 'Fare_FBin 9',\n",
      "       'Fare_FBin 10', 'Fare_FBin 11', 'Fare_FBin 12', 'Fare_FBin 13',\n",
      "       'Fare_FBin 14', 'Fare_FBin 15', 'Fare_FBin 16', 'Fare_FBin 17',\n",
      "       'Fare_FBin 18', 'Fare_FBin 19', 'Fare_FBin 20', 'Fare_FBin 21',\n",
      "       'Fare_FBin 22', 'Fare_FBin 23', 'Fare_FBin 24'],\n",
      "      dtype='object')\n",
      "/home/buckfae/Documents/DataScience/Titanic\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(x_test_df.columns)\n",
    "\n",
    "features = [f for f in x_train_df.columns if f != 'PassengerId']\n",
    "\n",
    "forest_train_x = x_train_df[features]\n",
    "forest_test_x = x_test_df[features]\n",
    "\n",
    "# Random Forest\n",
    "forestModel = RandomForestClassifier(n_estimators = 100, max_depth=5, random_state=1)\n",
    "forestModel.fit(forest_train_x, y_train_df)\n",
    "predictions = forestModel.predict(forest_test_x)\n",
    "output = pd.DataFrame({'PassengerId': x_test_df.PassengerId, 'Survived': predictions})\n",
    "print(os.getcwd())\n",
    "output.to_csv('data/submission.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "outputs": [],
   "source": [
    "def create_nn(input_shape, hidden_shapes):\n",
    "    assert len(hidden_shapes) > 0\n",
    "    # Input Layer\n",
    "    network_architecture = [nn.Linear(input_shape, hidden_shapes[0]), nn.ReLU()]\n",
    "\n",
    "    # Hidden Layer\n",
    "    hidden = [[nn.Linear(hidden_shapes[i], hidden_shapes[i + 1]), nn.ReLU()] for i in range(len(hidden_shapes) - 1)]\n",
    "    for layer in hidden:\n",
    "        for item in layer:\n",
    "            network_architecture.append(item)\n",
    "\n",
    "    # Output Layer\n",
    "    network_architecture += [nn.Linear(hidden_shapes[-1], 1), nn.Sigmoid()]\n",
    "    return nn.Sequential(*network_architecture)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor features: Index(['IsPClass1', 'IsPClass2', 'IsPClass3', 'Female', 'Male', 'SibSp',\n",
      "       'Age_Bin 0', 'Age_Bin 1', 'Age_Bin 2', 'Age_Bin 3', 'Age_Bin 4',\n",
      "       'Age_Bin 5', 'Age_Bin 6', 'Age_Bin 7', 'Age_Bin 8', 'Age_Bin 9',\n",
      "       'Age_missing value', 'Fare_FBin 0', 'Fare_FBin 1', 'Fare_FBin 2',\n",
      "       'Fare_FBin 3', 'Fare_FBin 4', 'Fare_FBin 5', 'Fare_FBin 6',\n",
      "       'Fare_FBin 7', 'Fare_FBin 8', 'Fare_FBin 9', 'Fare_FBin 10',\n",
      "       'Fare_FBin 11', 'Fare_FBin 12', 'Fare_FBin 13', 'Fare_FBin 14',\n",
      "       'Fare_FBin 15', 'Fare_FBin 16', 'Fare_FBin 17', 'Fare_FBin 18',\n",
      "       'Fare_FBin 19', 'Fare_FBin 20', 'Fare_FBin 21', 'Fare_FBin 22',\n",
      "       'Fare_FBin 23', 'Fare_FBin 24'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Dropping ID column\n",
    "x_train_df = x_train_df.drop(columns=['PassengerId'], axis=0)\n",
    "x_test_df = x_test_df.drop(columns=['PassengerId'], axis=0)\n",
    "x_train_df.head()\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "for train_row in x_train_df.values:\n",
    "    x_train.append(torch.tensor(train_row.astype(np.float32)))\n",
    "for train_row in y_train_df.values:\n",
    "    y_train.append(torch.tensor([train_row.astype(np.float32)]))\n",
    "\n",
    "print(f'Input tensor features: {x_train_df.columns}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: 42\n",
      "Sequential(\n",
      "  (0): Linear(in_features=42, out_features=64, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (7): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = x_train_df.shape[1]\n",
    "hidden_layers = [64, 64, 64]\n",
    "epochs = 100\n",
    "\n",
    "print(f'Input size: {input_size}')\n",
    "model = create_nn(input_size, hidden_layers)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0000: 0484 / 0407 - Loss: 0.6924033796\n",
      "Episode: 0010: 0549 / 0342 - Loss: 0.6642561893\n",
      "Episode: 0020: 0549 / 0342 - Loss: 0.6548432316\n",
      "Episode: 0030: 0549 / 0342 - Loss: 0.6433532642\n",
      "Episode: 0040: 0549 / 0342 - Loss: 0.6204391499\n",
      "Episode: 0050: 0590 / 0301 - Loss: 0.5748073137\n",
      "Episode: 0060: 0690 / 0201 - Loss: 0.5202306847\n",
      "Episode: 0070: 0704 / 0187 - Loss: 0.4829985039\n",
      "Episode: 0080: 0703 / 0188 - Loss: 0.4638215694\n",
      "Episode: 0090: 0710 / 0181 - Loss: 0.4518913827\n",
      "Episode: 0100: 0715 / 0176 - Loss: 0.4422046982\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.0003)\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "for e in range(epochs + 1):\n",
    "\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "\n",
    "    for x, y in zip(x_train, y_train):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "\n",
    "        if output[0] > 0.5 and y == 1 or output[0] < 0.5 and y == 0:\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "\n",
    "        loss = loss_func(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        avg_loss = running_loss / len(x_train)\n",
    "        print(f'Episode: {e:04d}: {correct:04d} / {wrong:04d} - Loss: {avg_loss:.10f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}